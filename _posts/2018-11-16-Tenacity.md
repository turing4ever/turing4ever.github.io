---
title: Retry with Tenacity
key: 20181116 
tags: 
published: false
---

The essential part of building reliable data pipeline is error handling. Especially when you are dealing with quite a lot of data from third party APIs.
A lot of time and efforts will go into dealing with failed API calls gracefully. I just stumbled upon one Python library that helps to relive some of the pains. 

Tenacity is a pythonic library that provides facilities for detecting failures and defining retrying strategies. It provides additional tooling in logging and recording statistics as well. 
Here is some sample code to illustrate how it works. 
```python
import logging
import sys
from tenacity import retry, wait_random, stop_after_attempt, before_log

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
LOGGER = logging.getLogger(__name__)
@retry(reraise=True,
       stop=stop_after_attempt(4),
       wait=wait_random(min=1, max=2),
       before=before_log(LOGGER, logging.DEBUG))
def wait_random_1_to_2_s():
    raise Exception

if __name__ == '__main__':
    try:
        wait_random_1_to_2_s()
    except Exception:
        pass
    print(wait_random_1_to_2_s.retry.statistics)

```

Because the retry mechanism can be added to existing code as decorators, it's much easier to refactor existing code. By specifying parameters such as 
`reraise`, `stop`, `wait` and `before`, you can define the retry handles exception, how many retry attempts, how long to wait between retries and how to log 
the attempts. In the end, you can access the statistics of the retries in `retry` object. For more details on how this library works, please read the [docs](https://tenacity.readthedocs.io/en/latest/).

A side note: the example code in [before and after retry and logging](https://tenacity.readthedocs.io/en/latest/#before-and-after-retry-and-logging) doesn't really work. 
You need to either add a handler to the logger or use basicConfig, otherwise there won't be anything output to stdout.   
